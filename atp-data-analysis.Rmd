---
title: "ATP Data Analysis"
authors: Matija Pavlović, Barbara Pašalić, Jelena Kulišić, Marko Miljković
date: "19.1.2024."
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Instalacija potrebnih paketa.

```{r}
# install.packages("dplyr")
# install.packages("lubridate")
# install.packages("ggplot2")
# install.packages("caret")
# install.packages("nortest")
# install.packages("fastDummies")
# install.packages("car")
```

Učitavanje biblioteka.

```{r message=FALSE}
library(dplyr)
library(lubridate)
library(ggplot2)
library(caret)
library(nortest)
library(fastDummies)
library(car)
```

Učitavanje i opis podataka

```{r}
all_matches <- data.frame()
for (year in 1991:2023) {
  file_name <- paste0("dataset/atp_matches_", year, ".csv")
  matches_year <- read.csv(file_name, stringsAsFactors = FALSE)
  all_matches <- rbind(all_matches, matches_year)
}

dim(all_matches)
```
Skup podataka sadrži informacije o 104682 teniska meča održana od 1991. do 2023. godine uključivo. Svaki meč opisan je s 49 ispod navedenih značajki:

```{r}
names(all_matches)
```

## Zadatak 1. Kakva je distribucija mečeva na specifičnim podlogama u različitim godišnjim dobima?

```{r echo=FALSE}
t1 <- all_matches %>%
  filter(!is.na(surface) & !is.na(tourney_date) & surface != "")

t1 <- select(t1, surface, tourney_date)

t1$tourney_date <- as.Date(as.character(t1$tourney_date), format = "%Y%m%d", origin = "1970-01-01")
t1$month <- month(t1$tourney_date)
t1$season <- case_when(
  t1$month %in% c(3, 4, 5) ~ "Spring",
  t1$month %in% c(6, 7, 8) ~ "Summer",
  t1$month %in% c(9, 10, 11) ~ "Fall",
  t1$month %in% c(12, 1, 2) ~ "Winter",
  TRUE ~ "Unknown"
)

surface_counts <- table(t1$season, t1$surface)
surface_counts_df <- as.data.frame(surface_counts)
names(surface_counts_df) <- c("Season", "Surface", "Frequency")

ggplot(t1, aes(x = season, fill = factor(season))) +
  geom_bar() +
  facet_wrap(~ surface, scales = "free") +
  labs(title = "Season Frequencies for Each Surface", x = "Season", y = "Frequency") +
  theme_minimal()
```

U prvom histogramu prikazana je raspodjela teniskih mečeva prema godišnjim dobima na podlozi od tepiha. Podloga od tepiha najmanje je korištena podloga za igranje mečeva. Najčešće se podloga od tepiha koristila u jesen, dosta rjeđe zimi, zatim na proljeće, a najmanje se mečeva na podlozi od tepiha igra na ljeto. 

Sljedeći histogram predstavlja raspodjelu mečeva prema godišnjim dobima na zemljanoj podlozi. Mečevi na zemlji najčešće se igraju u proljetnom dijelu sezone. Dosta manje mečeva igra se na ljeto zatim otprilike podjednako na jesen i zimi. 

Treći histogram opisuje distribuciju teniskih mečeva prema godišnjim dobima na travi. Teniski mečevi na travi igraju se uglavnom ljeti, a svega nekoliko mečeva igra se u preostalim godišnjim dobima. 

U posljednjem histogramu promatrana je raspodjela mečeva prema godišnjim dobima na tvrdoj podlozi. Sveukupno najviše mečeva igra se na tvrdoj podlozi te je raspodjela prema godišnjim dobima manje izražena nego kod drugih podloga. Najviše mečeva na tvrdoj podlozi održava se zimi, zatim u ljeto pa na jesen te najmanje u proljetnom dijelu sezone.

```{r echo=FALSE}
ggplot(surface_counts_df, aes(x = Surface, y = Frequency, fill = Surface)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~Season, scales = "free") +
  labs(title = "Surface Frequencies for Each Season", x = "Surface", y = "Frequency") +
  theme_minimal()
```

Prvi histogram prikazuje raspodjelu mečeva prema podlogama u jesen. Uvjerljivo najviše mečeva u jesen održava se na tvrdoj podlozi. Dosta manje mečeva igra se na podlozi od tepiha, a nešto malo manje na zemlji. Najmanje mečeva u jesenskom dijelu sezone igra se na travi. 

Idući histogram prikazuje raspodjelu mečeva prema podlogama u proljeće. U proljetnom dijelu sezone uvjerljivo najviše teniskih mečeva igra se na podlozi od zemlje. Više od dvostruko manje mečeva održava se na tvrdoj podlozi. Jako malo mečeva održava se na podlozi od tepiha, a još manje na travi. 

U trećem histogramu promatramo raspodjelu mečeva prema podlogama tijekom ljeta. Najviše mečeva održava se na tvrdoj podlozi, zatim na travi pa na podlozi od zemlje. Svega nekoliko mečeva igra se na podlozi od tepiha. 

Zadnji histogram opisuje raspodjelu mečeva prema podlogama zimi. Tijekom zime prednjače mečevi na tvrdoj podlozi. Dosta manje mečeva igra se na zemlji, zatim na podlozi od tepiha te najmanje na travi.


## Zadatak 2. Postoji li značajna razlika u prosječnom broju dvostrukih pogrešaka između mečeva odigranih na otvorenom u odnosu na mečeve odigrane na zatvorenom terenu?

Na početku ispisujemo statistiku o podatcima, prvo za mečeve odigrane na otvorenom pa na zatvorenom:

```{r echo=FALSE}
t2 <- all_matches %>%
  filter(!is.na(w_df) & !is.na(l_df) & !is.na(surface) & w_df != "" & l_df != "" & surface != "")
t2 <- select(t2, w_df, l_df, surface)
t2$court_type <- ifelse(t2$surface %in% c("Clay", "Grass", "Hard"), "Outdoor", "Indoor")

t2 <- t2 %>%
  mutate(df = w_df + l_df)


open_surface_data <- t2$df[t2$court_type == 'Outdoor']
closed_surface_data <- t2$df[t2$court_type == 'Indoor']

summary(open_surface_data)
summary(closed_surface_data)
```

S obzirom na veliku razliku između mean i max. vrijednosti pronalazimo outliere te ih izbacujemo iz podataka:

```{r echo=FALSE}
# Funkcija za izbacivanje outliera
remove_outliers <- function(data) {
  q <- quantile(data, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  lower_bound <- q[1] - 1.5 * iqr
  upper_bound <- q[2] + 1.5 * iqr
  
  data_filtered <- data[data >= lower_bound & data <= upper_bound]
  
  return(data_filtered)
}

open_surface_data_no_outliers <- remove_outliers(open_surface_data)
closed_surface_data_no_outliers <- remove_outliers(closed_surface_data)

summary(open_surface_data_no_outliers)
summary(closed_surface_data_no_outliers)
```

Nakon toga stvaramo bar plot za usporedbu prosječnog broja dvostrukih pogrešaka ovisno o tome jesu li mečevi odigrani na otvorenom ili zatvorenom: 

```{r echo=FALSE}
# BAR PLOT BEZ OUTLIERA
avg_open_surface_data <- mean(open_surface_data_no_outliers)
avg_closed_surface_data <- mean(closed_surface_data_no_outliers)
avg_data <- c(avg_open_surface_data, avg_closed_surface_data)
barplot(avg_data, 
        names.arg=c("Outdoor", "Indoor"),
        main="Average Double Faults on Outdoor and Indoor Type Courts",
        xlab="Court type",
        ylab="Average number of double faults",
        col=c("lightblue", "lightgreen"))
```
Iz barplota vidljivo je da su prosjecne dvostruke pogreške podjednake na unutarnjim i vanjskim terenima.

Zatim provjeravamo ukazuje li boxplot na moguću značajnu razliku.

```{r echo=FALSE}

min_length <- min(length(open_surface_data_no_outliers), length(closed_surface_data_no_outliers))
df <- data.frame(
        court_type = rep(c("Outdoor", "Indoor"), each = min_length),
        df = c(open_surface_data_no_outliers[1:min_length], closed_surface_data_no_outliers[1:min_length])
)

ggplot(df, aes(x = court_type, y = df)) +
        geom_boxplot(fill = "lightblue", color = "blue") +
        labs(title = "Comparison of Outdoor and Indoor Court Types",
             x = "Court Type",
             y = "Total DataFrame") +
        theme_minimal()
```

Boxplot ukazuje na to da nema razlike između prosječnog broja dvostrukih pogrešaka između mečeva
odigranih na otvorenom i zatvorenom. 
Kako bismo provjerili možemo li prihvatiti nultu hipotezu koja pretpostavlja da nema razlike, provest ćemo t-test.
Najprije moramo provjeriti pretpostavke o normalnoj distribuciji i homogenosti varijanci. Normalnu distribuciju prvo provjeravamo pomoću qq-plota, a zatim i Lilliefors testom.

```{r}
qqnorm(open_surface_data_no_outliers, main = "Normal Q-Q Plot for outdoor courts")
qqline(open_surface_data_no_outliers, col = "red", lwd = 2)


qqnorm(closed_surface_data_no_outliers, main = "Normal Q-Q Plot for indoor courts")
qqline(closed_surface_data_no_outliers, col = "blue", lwd = 2)

```

Iz qq-plota vidljivo je da su distribucije približno normalne uz minimalna odstupanja pa zbog velike dimenzije uzoraka možemo reći da je pretpostavka o normalnosti zadovoljena i za mečeve na otvorenom i za mečeve u zatvorenom.
Zatim provodimo Lilliefors test: 

```{r}
lillie_test_outdoor <- lillie.test(open_surface_data_no_outliers)
lillie_test_indoor <- lillie.test(closed_surface_data_no_outliers)
```
```{r echo=FALSE}
print(lillie_test_outdoor)
print(lillie_test_indoor)
```
Prema Lilliefors testu odbacili bi pretpostavku o normalnosti distribucije, ali zbog značajno velike količine podataka i centralnog graničnog teorema zaključujemo da je pretpostavka ipak zadovoljena.



Provedimo sada F-test za provjeru homogenosti varijanci: 

```{r}
var_test_result <- var.test(open_surface_data_no_outliers, closed_surface_data_no_outliers)
print(var_test_result)
```

F-test za usporedbu varijanci pokazuje da postoji razlika u varijancama između otvorenog terena i zatvorenog terena (p-vrijednost < 0.05).

Provjerimo jesu li veličine uzoraka podjednake.

```{r}
print(length(open_surface_data_no_outliers))
print(length(closed_surface_data_no_outliers))
```
Kako veličine uzoraka nisu približno jednake ne možemo pretpostaviti homogenost varijanci na temelju toga što imamo mnogo podataka pa koristimo neparametarsku alternativu t-testu - Wilcoxon rank-sum test.

```{r}
#t.test(open_surface_data, closed_surface_data, var.equal = TRUE)
print(wilcox.test(open_surface_data_no_outliers, closed_surface_data_no_outliers, alternative = "two.sided"))
```

Wilcoxon rank-sum test ne pokazuje značajnu razliku u srednjim vrijednostima (medijanama) između otvorenog i zatvorenog terena (p-vrijednost > 0.05, dakle ne možemo odbaciti nultu hipotezu).

Na temelju ovih rezultata, možemo zaključiti da nema značajne razlike u prosječnom broju dvostrukih pogrešaka između mečeva odigranih na otvorenom terenu i mečeva odigranih na zatvorenom terenu.


## Zadatak 3. Ima li razlike u broju serviranih asova na različitim podlogama?	

Analizirajmo deskriptivnu statistiku za svaku od podloga:

```{r echo=FALSE}
t3 <- all_matches %>%
  filter(!is.na(w_ace) & !is.na(l_ace) & !is.na(surface) & w_ace != "" & l_ace != "" & surface != "")
t3 <- select(t3, surface, w_ace, l_ace)
t3 <- t3 %>%
  mutate(aces = w_ace + l_ace)

cat("Summary for Hard Surface:\n")
print(summary(t3$aces[t3$surface == 'Hard']))

cat("\nSummary for Clay Surface:\n")
print(summary(t3$aces[t3$surface == 'Clay']))

cat("\nSummary for Carpet Surface:\n")
print(summary(t3$aces[t3$surface == 'Carpet']))

cat("\nSummary for Grass Surface:\n")
print(summary(t3$aces[t3$surface == 'Grass']))
```
Izbacit ćemo stršeće podatke čija se prisutnost jasno vidi u maksimumu na svakoj od podloga te opet ispisati statistiku.

```{r}
remove_outliers <- function(data) {
  q <- quantile(data, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  lower_bound <- q[1] - 1.5 * iqr
  upper_bound <- q[2] + 1.5 * iqr
  
  data_filtered <- data[data >= lower_bound & data <= upper_bound]
  
  return(data_filtered)
}

hard_aces = remove_outliers(t3$aces[t3$surface == 'Hard'])
carpet_aces = remove_outliers(t3$aces[t3$surface == 'Carpet'])
clay_aces = remove_outliers(t3$aces[t3$surface == 'Clay'])
grass_aces = remove_outliers(t3$aces[t3$surface == 'Grass'])

```
```{r echo=FALSE}
cat("Summary for Hard Surface:\n")
print(summary(hard_aces))

cat("\nSummary for Clay Surface:\n")
print(summary(clay_aces))

cat("\nSummary for Carpet Surface:\n")
print(summary(carpet_aces))

cat("\nSummary for Grass Surface:\n")
print(summary(grass_aces))
```
Sada možemo i vizualizirati prosječni broj asova serviranih na svakoj od podloga kako bi uočili potencijalnu razliku.
```{r}
combined_data <- data.frame(
  surface = rep(c("Hard", "Carpet", "Clay", "Grass"), 
                c(length(hard_aces), length(carpet_aces), length(clay_aces), length(grass_aces))),
  aces = c(hard_aces, carpet_aces, clay_aces, grass_aces)
)

ggplot(combined_data, aes(x = surface, y = aces, fill = surface)) +
  stat_summary(fun = "mean", geom = "bar") +
  labs(title = "Average Served Aces by Surface",
       x = "Surface",
       y = "Aces") +
  theme_minimal()
```
Iz barplota može se naslutiti da se zaista servira više asova na nekim površinama. Provjerimo je li to zaista tako koristeći ANOVA test. Nulta hipoteza jest da nema razlika u broju serviranih asova na različitim površinama. Kako bismo mogli provesti ANOVA statistički test moramo provjeriti jesu li zadovoljene pretpostavke o normalnosti distribucije i homogenosti varijanci za svaku od podloga.

1. provjera normalne distribucije

Prvo ćemo iscrtati histograme serviranih asova za svaku od površina:
```{r}
par(mfrow = c(2, 2))
for (surface in unique(combined_data$surface)){
hist(combined_data$aces[combined_data$surface==surface],
main = paste("Histogram of served aces on" , surface),
xlab = "Number of Served Aces",
ylab = "Frequency")
}
```

Iz histograma distribucije na svim podlogama čine se približno normalne osim na zemlji(Clay) koja ima nešto veće odstupanje.
Pretpostavit ćemo da je distribucija normalna s obzirom na to da su uzorci prilično veliki za svaku od grupa.

2. provjera homogenosti varijanci

Homogenost varijanci provjerava se Bartlettovim testom:
```{r}
bartlett.test(combined_data$aces ~ combined_data$surface)
```
Bartlettov test ukazuje na to da varijance nisu homogene no zbog velike količine podataka provjerimo koliko se razlikuju veličine uzoraka za svaku od podloga i njihove varijance.
```{r}
length(hard_aces)
length(carpet_aces)
length(clay_aces)
length(grass_aces)
```
```{r}
var((combined_data$aces[combined_data$surface=='Carpet']))
var((combined_data$aces[combined_data$surface=='Hard']))
var((combined_data$aces[combined_data$surface=='Clay']))
var((combined_data$aces[combined_data$surface=='Grass']))
```
Svaka grupa ima preko 5000 podataka i postoje odstupanja u varijancama no ANOVA je robusna na manja odstupanja homogenosti uz dovoljno velik sample size stoga ćemo ipak provesti i taj test radi usporedbe.
Nulta hipoteza jest da nema razlike u broju serviranih asova na različitim podlogama.
```{r}
res <- aov(aces~surface, data=combined_data)
summary(res)
```
P-vrijednost manja je od 0.05 stoga možemo odbaciti nultu hipotezu, odnosno postoji razlika u serviranim asovima na različitim podlogama.

Provedimo i Kruskal-Wallis koji je neparametarska alternativa ANOVA testu i koristi se kad nisu zadovoljene pretpostavke o normalnosti i homogenosti varijanci.
```{r}
kruskal.test(aces~surface, data=combined_data)
```

Nakon provedenog testa također dobivamo p-vrijednost manju od 0.05 što znači da postoji razlika u broj serviranih asova u odnosu na podlogu. Intuitivno ovaj rezultat ima smisla jer loptica ne odskače jednako od svih podloga, npr. na zemljanoj podlozi loptica se sporije odbija i obično zadržava niže dok se na travi odbija brzo.


## Zadatak 4. Kakva je veza između vrste terena i vjerojatnosti da će mečevi otići u peti set?

Postavljamo nultu hipotezu kako ne postoji statistički značajne veze između vrste terena i vjerojatnosti da će mečevi otići u peti set, a alternativna hipoteza sugerira prisutnost takve veze. Kako bismo testirali ovu hipotezu, koristit ćemo $\chi^2$ test. 

Najprije, provjeravamo pretpostavke kako bismo osigurali ispravnu primjenu testa. 

Omogućena je nezavisnost podataka jer rezultat jednog teniskog meča ne utječe na rezultat drugog meča. 

Također, osiguravamo da su nam podaci kategorički, klasifikacijom vrsta terena i ishoda mečeva u diskretne kategorije. 
Stvaramo kontingencijsku tablicu: 


```{r}
t4 <- all_matches[all_matches$best_of == 5, ]
t4$sets_played <- sapply(strsplit(as.character(t4$score), ""), function(x) sum(x == "-"))

contingency_table <- table(t4$surface, t4$sets_played == 5)
print(contingency_table)
```

Kontingencijskoj tablici dodajemo sume redaka i stupaca: 

```{r echo=FALSE}
contingency_with_sum = addmargins(contingency_table)
print(contingency_with_sum)
```

Još jedna pretpostavka testa je da očekivana frekvencija pojedinog razreda mora biti veća ili jednaka 5, stoga i to provjeravamo: 

```{r echo=FALSE}
for (col_names in colnames(contingency_with_sum)){
  for (row_names in rownames(contingency_with_sum)){
    if (!(row_names == 'Sum' | col_names == 'Sum') ){
      cat('Očekivane frekvencije za razred ',col_names,'-',row_names,': ',(contingency_with_sum[row_names,'Sum'] * contingency_with_sum['Sum',col_names]) / contingency_with_sum['Sum','Sum'],'\n')
    }
  }
}
```

Sve očekivane pretpostavke su zadovoljene, nastavljamo sa $\chi^2$ testom.

```{r}
chi_square_result <- chisq.test(contingency_table)
print(chi_square_result)
```

Rezultati $\chi^2$ testa ukazuju na to da ne postoji statistički značajna veza između vrste terena na kojem se održavaju teniski mečevi i vjerojatnosti da će mečevi otići u peti set (p-vrijednost = 0.361). S obzirom na p-vrijednost veću od 0.05, ne odbacujemo nultu hipotezu. 

## Zadatak 5. Možemo li procijeniti broj asova koje će igrač odservirati u tekućoj godini (zadnjoj dostupnoj sezoni) na temelju njegovih rezultata iz prethodnih sezona?	

Kako bismo predvidjeli broj asova za nekog igrača prvo moramo sagledati koje bi sve značajke mogle utjecati na broj odserviranih asova:

-   Visina igrača
-   Starost igrača
-   Rank igrača
-   Broj servi u sezoni
-   Broj uspješnih prvih servi
-   Broj osvojenih prvih servi

S obzirom da se podatci odnose pojedinačne mečeve, potrebno ih je agregirati za svakog igrača na razini sezone. Prilikom agregacije uzet ćemo srednju vrijednost za starost i rank igrača dok ćemo ostale statistike o servi sumirati. Kako bi dobili dojam o odnosu ovih varijabli i broja asova prikazat ćemo ih pojedinačno grafički pomoću scatter plota.

```{r echo=FALSE}

# Create a new dataframe with selected features
features <- c("tourney_id", "winner_id", "loser_id", "winner_name", "loser_name", "w_ace", "l_ace", "winner_ht", "loser_ht", "winner_age", "loser_age", "w_1stIn", "l_1stIn", "w_svpt", "l_svpt", "w_svpt", "l_svpt", "w_1stWon", "l_1stWon", "winner_rank", "loser_rank")

aces.by.season <- all_matches %>% select(all_of(features))
aces.by.season <- na.omit(aces.by.season)

# Extract the year from the tourney_id
aces.by.season$year <- as.numeric(substring(aces.by.season$tourney_id, 1, regexpr("-", aces.by.season$tourney_id)-1))

drop <- c("tourney_id")
aces.by.season = aces.by.season[,!(names(aces.by.season) %in% drop)]

# Aggregate features by player and year, considering both winner and loser information
winner.aggregated.data <- aces.by.season %>%
  group_by(player_id = winner_id, name = winner_name, year, winner_ht) %>%
  summarize(
    aces = sum(w_ace),
    age = mean(winner_age),
    rank = mean(winner_rank),
    firstIn = sum(w_1stIn),
    firstWon = sum(w_1stWon),
    svpt = sum(w_svpt),
    .groups = 'drop'
  )

loser.aggregated.data <- aces.by.season %>%
  group_by(player_id = loser_id, name = loser_name, year, loser_ht) %>%
  summarize(
    aces = sum(l_ace),
    age = mean(loser_age),
    rank = mean(loser_rank),
    firstIn = sum(l_1stIn),
    firstWon = sum(l_1stWon),
    svpt = sum(l_svpt),
    .groups = 'drop'
  )

colnames(winner.aggregated.data)[colnames(winner.aggregated.data) == "winner_ht"] <- "height"
colnames(loser.aggregated.data)[colnames(loser.aggregated.data) == "loser_ht"] <- "height"

wl.aggregated.data <- rbind(winner.aggregated.data, loser.aggregated.data)

aces.by.season <- wl.aggregated.data %>%
  group_by(player_id, name, year, height) %>%
  summarize(
    aces = sum(aces),
    age = mean(age),
    rank = mean(rank),
    firstIn = sum(firstIn),
    firstWon = sum(firstWon),
    svpt = sum(svpt),
    .groups = 'drop'
  )

aces.by.season$invRank <- 1 / aces.by.season$rank
```

```{r scatter plots, echo = FALSE, out.height="33%", out.width="50%"}

plot(aces.by.season$height, aces.by.season$aces)

hist(aces.by.season$height)

plot(aces.by.season$age, aces.by.season$aces)

hist(aces.by.season$age)

plot(aces.by.season$rank , aces.by.season$aces)

plot(aces.by.season$svpt, aces.by.season$aces)

plot(aces.by.season$firstIn, aces.by.season$aces)

plot(aces.by.season$firstWon, aces.by.season$aces)
```
Starost i visina igrača naizgled imaju nelinearni odnos prema broju aseva. Međutim, ako ispišemo histograme starosti i visina vidimo da je taj odnos proizašao iz frekvencije pojavljivanja tih značajki. Ovo ne vrijedi u potpunosti za visine igrača, ali pokazalo se da visina nije znatno utjecala na točnost modela. Zbog toga te dvije značajke nećemo dalje uzimati u obzir.

Rank igrača ima snažan obrnuto proporcionalan odnos s brojem asova što intuitivno ima smisla. Bolji igrači će imati veći broj asova. Važno je uočiti da ovaj odnos nije linearan i te ćemo morati uzeti inverz ranka prilikom regresije.

Ukupan broj servi, prvih uspješnih i prvih osvojenih servi ima linearan odnos prema broju aseva. Također uočavamo da su ove tri značajke naizgled jako korelirane. To ćemo morati ispitati i po potrebi uzeti samo jedno od ovih značajki za našu regresiju.

Valja spomenuti da su u obzir još bili uzeti podatci o servama, ali u postotcima. Oni su imali sličan problem kao i starost i visina. Scatter plot u odnosu na broj asova je imao oblik normalne distribcije. Dominantna ruka također nije uzeta u obzir jer prednost koju ona donosi ovisi o dominantnoj ruci suparnika, a pošto su podatci agregirani prednosti i hendikepi dominantne ruke će se poništiti.

Provjerit ćemo naše pretpostavke koristeći model jednostavne regresije, po jedan za svaku značajku. Broj asova će biti zavisna varijabla

```{r jendostavna regresija, out.height="33%", out.width="50%"}
fit.invRank = lm(aces ~ invRank, data=aces.by.season)

fit.svpt = lm(aces ~ svpt, data=aces.by.season)

fit.firstIn = lm(aces ~ firstIn, data=aces.by.season)

fit.firstWon = lm(aces ~ firstWon, data=aces.by.season)

f = function(x, coeffs)
  return(coeffs[[1]] + + coeffs[[2]] * (1 / x))
plot(aces.by.season$rank, aces.by.season$aces)
curve(f(x, fit.invRank$coefficients), add = TRUE, col = "red")

plot(aces.by.season$svpt, aces.by.season$aces)
lines(aces.by.season$svpt , fit.svpt$fitted.values, col='red')

plot(aces.by.season$firstIn, aces.by.season$aces)
lines(aces.by.season$firstIn, fit.firstIn$fitted.values, col='red')

plot(aces.by.season$firstWon, aces.by.season$aces)
lines(aces.by.season$firstWon, fit.firstWon$fitted.values, col='red')
```

### Normalnost reziduala i homogenost varijance

Normalnost reziduala provjerit ćemo grafički pomoću histograma i qq plota te statistički pomoću Lillieforsovog testa.

```{r normalnost reziduala, echo = FALSE, out.height="33%", out.width="50%"}
# Normalnost reziduala za inverzni rank
plot(fit.invRank$residuals)

hist((fit.invRank$residuals))
hist(rstandard(fit.invRank))

qqnorm(rstandard(fit.invRank))
qqline(rstandard(fit.invRank))

plot(fit.invRank$fitted.values, fit.invRank$residuals)
plot(aces.by.season$year , fit.invRank$residuals)

lillie.test(rstandard(fit.invRank))

# Normalnost za broj osvojenih prvih servi, skoro identični rezultati i za
# ukupan broj servi i uspješnih prvih servi
plot(fit.firstWon$residuals)

hist((fit.firstWon$residuals))
hist(rstandard(fit.firstWon))

qqnorm(rstandard(fit.firstWon))
qqline(rstandard(fit.firstWon))

plot(fit.firstWon$fitted.values, fit.firstWon$residuals)
plot(aces.by.season$year , fit.firstWon$residuals)

lillie.test(rstandard(fit.firstWon))
```

Iz histograma i qq plota možemo zaključiti da reziduali ukupan broja servi, uspješnih prvih servi i osvojenih prvih servi značajno odstupaju ali nalikuju na normalno distribuciju dok za inverz ranka reziduali više nalikuju eksponencijalnoj distribuciji nego normalnoj.

Također treba prijetiti da za ukupan broj servi, uspješnih prvih servi i osvojenih prvih servi u ovisnosti o predviđanjima reziduali pokazuju heterogenost varijance, šire se povećanjem $\hat{y}$. Međutim u ovisnosti o godinama reziduali pokazuju homogenu varijancu.

### Korelacija značajki

Unatoč neobećavajućim rezultatima ispitaivanja normalnosti i homogenosti varijance reziduala pokušat ćemo napraviti regresiju nad skupom relevantnih značajki. Kako bi to napravili prvo moramo odrediti koje su značajke korelirene.

```{r korelacija znacajki}
cor(cbind(aces.by.season$aces, aces.by.season$invRank, aces.by.season$svpt, aces.by.season$firstIn, aces.by.season$firstWon))
```

Kao što smo i pretpostavili ranije, ukupan broj servi, uspješnih prvih servi i osvojenih prvih servi pokasuzuju snažnu pozitivnu korelaciju. Stoga ćemo od te tri značjke uzeti samo ukupan broj osvojenih prvih srevi jer ima najveću korelaciju s brojem asova od te tri.

Inverzni rank također pokazuje značajnu korelaciju s ostatkom značajki.

```{r multi}
fit.multi = lm(aces ~ invRank + firstWon, data=aces.by.season)
summary(fit.multi)
```
Iz modela možemo vidjeti da rank igrača jako slabo utječe na objašnjavanje varijance podataka. Stoga ćemo pokušati pretvoriti rank igrača u kategoričku varijablu na način da svrtamo igrače u sljedeće kategorije:
  - Rank   1 -  20
  - Rank  21 -  50
  - Rank  50 - 100
  - Rank 100+
  
```{r categoric rank}
aces.by.season <- aces.by.season %>%
  mutate(rankCat = case_when(
    rank < 25 ~ 1,
    rank < 50 ~ 2,
    rank < 75 ~ 3,
    rank < 100 ~ 4,
    TRUE ~ 5
  ))

boxplot(aces~rankCat, data=aces.by.season)
```

```{r rank category model}
aces.by.season.d = dummy_cols(aces.by.season, select_columns = 'rankCat')

fit.multi.d = lm(aces ~ firstWon + rankCat_1 + rankCat_2 + rankCat_3 + rankCat_4, data = aces.by.season.d)
summary(fit.multi.d)
```
Ova metoda nažalost također nije dala nikakvo značajno poboljšanje. Međutim postoji još jedan način da poboljšamo rezultate a to je uvođenje nove zakašnjele varijable. Naime pretpostavljamo da će broj aseva za nekog igrača biti jako povezan s brojem aseva koje je ostavrio u prošloj sezoni. Zato ćemo uvesti novu značajku prevAces u naš model.

```{r prevAces}
aces.by.season.d$prevAces = c(NA, aces.by.season.d$aces[1:length(aces.by.season.d$aces)-1])

fit.multi.timelag = lm(aces ~ firstWon + rankCat_1 + rankCat_2 + rankCat_3 + rankCat_4 + prevAces, data = aces.by.season.d)
summary(fit.multi.timelag)
```
Ovime smo dobili osjetno bolji model. Za kraj ćemo još primjeniti model za nekoliko igrača da vidimo kako radi.

```{r example}
player.samples <- aces.by.season.d[sample(nrow(aces.by.season.d), 10),]

name <- player.samples$name
year <- player.samples$year
target_aces <- player.samples$aces
prediction_aces <- predict(fit.multi.timelag, newdata = player.samples)

print(data.frame(name, year, target_aces, prediction_aces))
```

Model na žalost ne radi sjajno, ali to je i za očekivati jer su narušeni uvjeti normalnosti i homogenosti varijanci reziduala. Za ovaj problem potreban je složeniji model.